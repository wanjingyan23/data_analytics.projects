{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b78ab52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0a0cba",
   "metadata": {},
   "source": [
    "## Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80d37336",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv('/Users/annaywj/Desktop/SDSU/BDA600/Capstone/sd_weather_2018_2024_combined.csv')\n",
    "crash = pd.read_csv('/Users/annaywj/Desktop/SDSU/BDA600/Capstone/TIMS_SD_Crashes2013-2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df65fb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['datetime'] = pd.to_datetime(weather['datetime'], errors='coerce')\n",
    "crash['COLLISION_DATE'] = pd.to_datetime(crash['COLLISION_DATE'], errors='coerce')\n",
    "\n",
    "# Filter crash data for 2018â€“2024\n",
    "crash_filtered = crash[(crash['COLLISION_DATE'].dt.year >= 2018) &\n",
    "                          (crash['COLLISION_DATE'].dt.year <= 2024)].copy()\n",
    "\n",
    "# Aggregate crash data by date\n",
    "daily_crashes = crash_filtered.groupby('COLLISION_DATE').agg(\n",
    "    TOTAL_CRASHES=('CASE_ID', 'count'),\n",
    "    AVG_SEVERITY=('COLLISION_SEVERITY', 'mean')\n",
    ").reset_index().rename(columns={'COLLISION_DATE': 'datetime'})\n",
    "\n",
    "# Merge with weather data\n",
    "merged_weather = pd.merge(weather, daily_crashes, on='datetime', how='inner')\n",
    "\n",
    "# Select weather predictors and target\n",
    "weather_features = ['humidity', 'cloudcover', 'windspeed', 'precip']\n",
    "target_column = 'AVG_SEVERITY'\n",
    "\n",
    "# Drop missing values\n",
    "regression_ready = merged_weather[weather_features + [target_column]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d763ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.10411692103061565,\n",
       " cloudcover    0.359832\n",
       " humidity      0.321860\n",
       " windspeed     0.269387\n",
       " precip        0.048921\n",
       " dtype: float64,\n",
       " <class 'statsmodels.iolib.table.SimpleTable'>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = regression_ready[weather_features]\n",
    "y = regression_ready[target_column]\n",
    "\n",
    "# Add constant for OLS regression\n",
    "X_ols = sm.add_constant(X)\n",
    "ols_model = sm.OLS(y, X_ols).fit()\n",
    "\n",
    "# Random Forest Regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "rf_r2 = r2_score(y_test, y_pred)\n",
    "rf_importance = pd.Series(rf_model.feature_importances_, index=weather_features).sort_values(ascending=False)\n",
    "\n",
    "# Output results\n",
    "ols_summary = ols_model.summary()\n",
    "rf_r2, rf_importance, ols_summary.tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620ac4e7",
   "metadata": {},
   "source": [
    "## SOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40482a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "road = pd.read_csv('/Users/annaywj/Downloads/SOC_-_Local_Roads__Speed_and_Volume_20250423.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2e74200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.10429588222092101,\n",
       " AADT_Change        0.309248\n",
       " Speed_2022_MPH     0.270044\n",
       " Speed_Change       0.259344\n",
       " Lanes              0.089369\n",
       " Speed_Limit_MPH    0.071995\n",
       " dtype: float64,\n",
       " <class 'statsmodels.iolib.table.SimpleTable'>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "crash['COLLISION_DATE'] = pd.to_datetime(crash['COLLISION_DATE'], errors='coerce')\n",
    "crash_filtered = crash[(crash['COLLISION_DATE'].dt.year >= 2018) & \n",
    "                       (crash['COLLISION_DATE'].dt.year <= 2024)].copy()\n",
    "\n",
    "# Drop rows without location\n",
    "crash_filtered = crash_filtered.dropna(subset=['POINT_X', 'POINT_Y'])\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "crash_gdf = gpd.GeoDataFrame(\n",
    "    crash_filtered,\n",
    "    geometry=gpd.points_from_xy(crash_filtered['POINT_X'], crash_filtered['POINT_Y']),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Step 2: Convert road data to GeoDataFrame\n",
    "road = road.dropna(subset=['geometry'])\n",
    "road_gdf = gpd.GeoDataFrame(road, geometry=gpd.GeoSeries.from_wkt(road['geometry']), crs=\"EPSG:4326\")\n",
    "\n",
    "# Step 3: Project both to meters\n",
    "crash_gdf = crash_gdf.to_crs(epsg=3857)\n",
    "road_gdf = road_gdf.to_crs(epsg=3857)\n",
    "\n",
    "# Step 4: Use midpoint of road segment\n",
    "road_gdf['rep_point'] = road_gdf.geometry.representative_point()\n",
    "road_gdf.set_geometry('rep_point', inplace=True)\n",
    "\n",
    "# Step 5: Nearest neighbor match\n",
    "crash_coords = np.array(list(zip(crash_gdf.geometry.x, crash_gdf.geometry.y)))\n",
    "road_coords = np.array(list(zip(road_gdf.geometry.x, road_gdf.geometry.y)))\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=1, radius=50)\n",
    "nn.fit(road_coords)\n",
    "distances, indices = nn.kneighbors(crash_coords)\n",
    "\n",
    "within_50m = distances[:, 0] <= 50\n",
    "crash_gdf = crash_gdf[within_50m]\n",
    "matched_indices = indices[within_50m].flatten()\n",
    "\n",
    "# Step 6: Merge\n",
    "matched_roads_clean = road_gdf.reset_index().iloc[matched_indices].reset_index(drop=True).drop(columns=['geometry'])\n",
    "joined_df = pd.concat([crash_gdf.reset_index(drop=True), matched_roads_clean], axis=1)\n",
    "\n",
    "# Step 7: Aggregate\n",
    "aggregated = joined_df.groupby('osm_id').agg(\n",
    "    TOTAL_CRASHES=('CASE_ID', 'count'),\n",
    "    AVG_SEVERITY=('COLLISION_SEVERITY', 'mean'),\n",
    "    Lanes=('Lanes', 'first'),\n",
    "    Speed_Limit_MPH=('Speed Limit MPH', 'first'),\n",
    "    Speed_2022_MPH=('Speed 2022 MPH', 'first'),\n",
    "    Speed_Change=('1 year Speed % change', 'first'),\n",
    "    AADT_Change=('1 year AADT % change', 'first')\n",
    ").dropna()\n",
    "\n",
    "# Step 8: Regression\n",
    "X = aggregated[['Lanes', 'Speed_Limit_MPH', 'Speed_2022_MPH', 'Speed_Change', 'AADT_Change']]\n",
    "y = aggregated['AVG_SEVERITY']\n",
    "\n",
    "X_ols = sm.add_constant(X)\n",
    "ols_model = sm.OLS(y, X_ols).fit()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "rf_r2 = r2_score(y_test, y_pred)\n",
    "rf_importance = pd.Series(rf_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "# Output\n",
    "ols_summary = ols_model.summary()\n",
    "rf_r2, rf_importance, ols_summary.tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542e6ad2",
   "metadata": {},
   "source": [
    "## Ped_party & Ped_Victim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0767e341",
   "metadata": {},
   "outputs": [],
   "source": [
    "ped_parties = pd.read_csv('/Users/annaywj/Downloads/Ped_Parties.csv')\n",
    "ped_victims = pd.read_csv('/Users/annaywj/Downloads/Ped_Victims.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b1ee110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6957053396275799,\n",
       " INJURY_4.0         0.436046\n",
       " INJURY_1.0         0.228706\n",
       " INJURY_2.0         0.094561\n",
       " PARTY_AGE          0.090444\n",
       " VICTIM_AGE         0.089447\n",
       " INJURY_5.0         0.030886\n",
       " INJURY_7.0         0.014858\n",
       " AT_FAULT_BINARY    0.006772\n",
       " INJURY_3.0         0.004173\n",
       " INJURY_6.0         0.004107\n",
       " dtype: float64,\n",
       " <class 'statsmodels.iolib.table.SimpleTable'>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "socio_party_merged = ped_parties.merge(\n",
    "    crash[['CASE_ID', 'COLLISION_SEVERITY']],\n",
    "    on='CASE_ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Map AT_FAULT to binary\n",
    "socio_party_merged['AT_FAULT_BINARY'] = socio_party_merged['AT_FAULT'].map({'Y': 1, 'N': 0})\n",
    "\n",
    "# Step 2: Merge in victim data (victim-level table with PARTY + CRASH info)\n",
    "socio_party_victim_merged = socio_party_merged.merge(\n",
    "    ped_victims[['CASE_ID', 'PARTY_NUMBER', 'VICTIM_AGE', 'VICTIM_DEGREE_OF_INJURY']],\n",
    "    on=['CASE_ID', 'PARTY_NUMBER'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Step 3: One-hot encode victim injury severity\n",
    "socio_party_victim_merged = pd.get_dummies(\n",
    "    socio_party_victim_merged,\n",
    "    columns=['VICTIM_DEGREE_OF_INJURY'],\n",
    "    prefix='INJURY',\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "# Step 4: Prepare feature set\n",
    "model_features_victims = ['PARTY_AGE', 'VICTIM_AGE', 'AT_FAULT_BINARY'] + \\\n",
    "    [col for col in socio_party_victim_merged.columns if col.startswith('INJURY_')]\n",
    "\n",
    "model_data_victims = socio_party_victim_merged[model_features_victims + ['COLLISION_SEVERITY']].dropna()\n",
    "\n",
    "X = model_data_victims[model_features_victims]\n",
    "y = model_data_victims['COLLISION_SEVERITY']\n",
    "\n",
    "# Step 5: Run OLS\n",
    "X_ols = sm.add_constant(X)\n",
    "ols_model = sm.OLS(y, X_ols).fit()\n",
    "\n",
    "# Step 6: Random Forest Regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "rf_r2 = r2_score(y_test, y_pred)\n",
    "rf_importance = pd.Series(rf_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "# Output model results\n",
    "ols_summary = ols_model.summary()\n",
    "rf_r2, rf_importance, ols_summary.tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6932903d",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1348f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.11099561591030516,\n",
       " cloudcover    0.376267\n",
       " humidity      0.338181\n",
       " windspeed     0.285551\n",
       " dtype: float64,\n",
       " -0.1329219627770124,\n",
       " AADT_Change       0.382801\n",
       " Speed_Change      0.312471\n",
       " Speed_2022_MPH    0.304728\n",
       " dtype: float64,\n",
       " 0.648014207470236,\n",
       " INJURY_4.0    0.480172\n",
       " INJURY_1.0    0.251844\n",
       " INJURY_2.0    0.104129\n",
       " PARTY_AGE     0.084259\n",
       " VICTIM_AGE    0.079596\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_vars = ['cloudcover', 'humidity', 'windspeed']\n",
    "weather_final = merged_weather[['datetime', 'AVG_SEVERITY'] + weather_vars].dropna()\n",
    "\n",
    "# From road: aggregated per road segment with osm_id\n",
    "road_vars = ['AADT_Change', 'Speed_2022_MPH', 'Speed_Change']\n",
    "road_final = aggregated[road_vars + ['AVG_SEVERITY']].dropna()\n",
    "\n",
    "# From party/victim: victim-level merged with CRASH info\n",
    "party_victim_vars = ['PARTY_AGE', 'VICTIM_AGE', 'INJURY_1.0', 'INJURY_2.0', 'INJURY_4.0']\n",
    "victim_final = socio_party_victim_merged[party_victim_vars + ['COLLISION_SEVERITY']].dropna()\n",
    "\n",
    "# Rename severity columns to align\n",
    "weather_final = weather_final.rename(columns={'AVG_SEVERITY': 'severity'})\n",
    "road_final = road_final.rename(columns={'AVG_SEVERITY': 'severity'})\n",
    "victim_final = victim_final.rename(columns={'COLLISION_SEVERITY': 'severity'})\n",
    "\n",
    "# Step 2: Create separate models for each (different levels â€” can't merge directly)\n",
    "X_weather = weather_final[weather_vars]\n",
    "X_road = road_final[road_vars]\n",
    "X_victim = victim_final[party_victim_vars]\n",
    "y_weather = weather_final['severity']\n",
    "y_road = road_final['severity']\n",
    "y_victim = victim_final['severity']\n",
    "\n",
    "# Step 3: Train Random Forest models on each\n",
    "def train_rf_model(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    importance = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "    return r2, importance\n",
    "\n",
    "r2_weather, imp_weather = train_rf_model(X_weather, y_weather)\n",
    "r2_road, imp_road = train_rf_model(X_road, y_road)\n",
    "r2_victim, imp_victim = train_rf_model(X_victim, y_victim)\n",
    "\n",
    "r2_weather, imp_weather, r2_road, imp_road, r2_victim, imp_victim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c14dc730",
   "metadata": {},
   "outputs": [],
   "source": [
    "road_vars_final = ['1 year AADT % change', '1 year Speed % change', 'Speed 2022 MPH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "834bba70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7571386668620821,\n",
       " INJURY_4.0               0.394914\n",
       " INJURY_1.0               0.201598\n",
       " INJURY_2.0               0.093922\n",
       " cloudcover               0.046850\n",
       " Speed 2022 MPH           0.045934\n",
       " humidity                 0.044600\n",
       " windspeed                0.040745\n",
       " 1 year AADT % change     0.037626\n",
       " 1 year Speed % change    0.037290\n",
       " VICTIM_AGE               0.029706\n",
       " PARTY_AGE                0.026814\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features_corrected = [\n",
    "    'COLLISION_SEVERITY',\n",
    "    'cloudcover', 'humidity', 'windspeed',\n",
    "    '1 year AADT % change', '1 year Speed % change', 'Speed 2022 MPH',\n",
    "    'PARTY_AGE', 'VICTIM_AGE',\n",
    "    'INJURY_1.0', 'INJURY_2.0', 'INJURY_4.0'\n",
    "]\n",
    "\n",
    "# Subset and drop rows with missing data\n",
    "final_model_data = final_merged[final_features_corrected].dropna()\n",
    "\n",
    "# Define X and y\n",
    "X_final = final_model_data.drop(columns=['COLLISION_SEVERITY'])\n",
    "y_final = final_model_data['COLLISION_SEVERITY']\n",
    "\n",
    "# Train final random forest model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.3, random_state=42)\n",
    "final_rf = RandomForestRegressor(random_state=42)\n",
    "final_rf.fit(X_train, y_train)\n",
    "y_pred = final_rf.predict(X_test)\n",
    "final_r2 = r2_score(y_test, y_pred)\n",
    "final_importance = pd.Series(final_rf.feature_importances_, index=X_final.columns).sort_values(ascending=False)\n",
    "\n",
    "final_r2, final_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3134e052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Random Forest': 0.7571386668620821,\n",
       " 'Polynomial RF (2nd degree)': 0.7484760765122647,\n",
       " 'XGBoost': 0.7224903992631877,\n",
       " 'Gradient Boosting': 0.7068791645230569,\n",
       " 'Ridge': 0.6925502649149384,\n",
       " 'Lasso': -0.0007030623447410456}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Store models and their names\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(random_state=42, verbosity=0),\n",
    "    \"Ridge\": Ridge(random_state=42),\n",
    "    \"Lasso\": Lasso(random_state=42),\n",
    "    \"Polynomial RF (2nd degree)\": make_pipeline(\n",
    "        PolynomialFeatures(degree=2, include_bias=False), \n",
    "        RandomForestRegressor(random_state=42)\n",
    "    )\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "model_r2_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    model_r2_results[name] = r2_score(y_test, preds)\n",
    "\n",
    "model_r2_results_sorted = dict(sorted(model_r2_results.items(), key=lambda item: item[1], reverse=True))\n",
    "model_r2_results_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e676a252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tuned RF': 0.7528748562311883,\n",
       " 'RF + Interaction Term': 0.7606886345113067,\n",
       " 'RF with Weights': 0.7542038702072595,\n",
       " 'Stacked Ensemble': 0.7589460085698958}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "# 1. Hyperparameter Tuning for Random Forest\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [10, None],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "    \"max_features\": [\"sqrt\"]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(RandomForestRegressor(random_state=42), rf_param_grid, cv=3, n_jobs=-1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "rf_grid_best = rf_grid.best_estimator_\n",
    "rf_grid_r2 = r2_score(y_test, rf_grid_best.predict(X_test))\n",
    "\n",
    "# 2. Feature Enrichment (add interaction term: speed Ã— cloudcover)\n",
    "X_enriched = X_final.copy()\n",
    "X_enriched['speed_cloud_interaction'] = X_enriched['Speed 2022 MPH'] * X_enriched['cloudcover']\n",
    "X_train_e, X_test_e, y_train_e, y_test_e = train_test_split(X_enriched, y_final, test_size=0.3, random_state=42)\n",
    "rf_enriched = RandomForestRegressor(random_state=42)\n",
    "rf_enriched.fit(X_train_e, y_train_e)\n",
    "rf_enriched_r2 = r2_score(y_test_e, rf_enriched.predict(X_test_e))\n",
    "\n",
    "# 3. Sample Weighting by Severity Level\n",
    "weights = y_train.map({1: 3, 2: 2, 3: 1, 4: 1})  # More weight for fatal and severe\n",
    "rf_weighted = RandomForestRegressor(random_state=42)\n",
    "rf_weighted.fit(X_train, y_train, sample_weight=weights)\n",
    "rf_weighted_r2 = r2_score(y_test, rf_weighted.predict(X_test))\n",
    "\n",
    "# 4. Ensemble Stacking\n",
    "stack_model = StackingRegressor(\n",
    "    estimators=[\n",
    "        (\"rf\", RandomForestRegressor(random_state=42)),\n",
    "        (\"gb\", GradientBoostingRegressor(random_state=42)),\n",
    "        (\"ridge\", Ridge(random_state=42))\n",
    "    ],\n",
    "    final_estimator=Ridge()\n",
    ")\n",
    "stack_model.fit(X_train, y_train)\n",
    "stack_r2 = r2_score(y_test, stack_model.predict(X_test))\n",
    "\n",
    "# Return all updated RÂ² scores\n",
    "improved_model_r2 = {\n",
    "    \"Tuned RF\": rf_grid_r2,\n",
    "    \"RF + Interaction Term\": rf_enriched_r2,\n",
    "    \"RF with Weights\": rf_weighted_r2,\n",
    "    \"Stacked Ensemble\": stack_r2\n",
    "}\n",
    "improved_model_r2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
